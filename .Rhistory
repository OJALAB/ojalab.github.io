params_hat <- opt_result$par
beta_hat <- params_hat[1:3]
phi_hat <- params_hat[4:6]
# --- S4. Estimate Population Mean ---
# Estimator 1: Y_hat(X_U, known)
# (1/N) * sum_{i in U} E_hat[y_i | x_i]
mu_hat_pop <- U_X %*% beta_hat
Y_hat_1 <- mean(mu_hat_pop)
# Estimator 2: Y_hat(GREG)
# (1/N) * [ sum_{i in U} E_hat_pw[y_i | x_i] + sum_{k in S_NP} w_k * (y_k - E_hat_pw[y_k | x_k]) ]
# Need weights w_k = 1 / Pr(delta=1 | y_k, x_k; phi_hat)
pi_hat_S_NP <- pr_delta_given_y_x(
y = S_NP_data$y,
X = S_NP_X,
phi = phi_hat
)
w_hat_S_NP <- 1 / pi_hat_S_NP
# Need probability-weighted "B_pk" (beta_hat_pw)
beta_hat_pw <- tryCatch(
coef(lm(y ~ x1 + x2, data = S_NP_data, weights = w_hat_S_NP)),
error = function(e) beta_hat # Fallback
)
mu_hat_pw_pop <- U_X %*% beta_hat_pw
mu_hat_pw_S_NP <- S_NP_X %*% beta_hat_pw
greg_term_1 <- sum(mu_hat_pw_pop)
greg_term_2 <- sum(w_hat_S_NP * (S_NP_data$y - mu_hat_pw_S_NP))
Y_hat_2 <- (greg_term_1 + greg_term_2) / N_POP
# Estimator 4: Y_hat(MAR)
# Incorrectly assumes Pr(delta=1 | y, x) = Pr(delta=1 | x)
mar_model <- glm(delta ~ x1 + x2, data = U_data, family = "binomial")
pr_delta_mar <- predict(mar_model, newdata = S_NP_data, type = "response")
w_mar <- 1 / pr_delta_mar
Y_hat_4 <- weighted.mean(S_NP_data$y, w_mar)
# --- Store Results ---
results[i, "Y_true"] <- Y_true
results[i, "Y_hat_1_knownX"] <- Y_hat_1
results[i, "Y_hat_2_GREG"] <- Y_hat_2
results[i, "Y_hat_4_MAR"] <- Y_hat_4
results[i, "n_NP"] <- n_NP
results[i, "opt_status"] <- opt_result$status
if (i %% 10 == 0) {
cat(paste("... Completed simulation", i, "of", N_SIM, "\n"))
}
cat("Simulation complete. Analyzing results...\n\n")
# --- 5. Analyze and Display Results ---
# Filter out failed optimizations (status < 0)
failed_runs <- sum(results$opt_status < 0)
if (failed_runs > 0) {
cat(paste("Warning:", failed_runs, "simulation(s) failed to converge and were excluded.\n\n"))
results_clean <- results[results$opt_status > 0, ]
} else {
results_clean <- results
}
# Helper function to calculate stats
calculate_stats <- function(estimator_col, true_col) {
bias <- mean(estimator_col - true_col, na.rm = TRUE)
emp_var <- var(estimator_col, na.rm = TRUE)
mse <- mean((estimator_col - true_col)^2, na.rm = TRUE)
return(c(Bias = bias, "Emp. Var" = emp_var, MSE = mse))
}
# Calculate stats for each estimator
stats_1 <- calculate_stats(results_clean$Y_hat_1_knownX, results_clean$Y_true)
stats_2 <- calculate_stats(results_clean$Y_hat_2_GREG, results_clean$Y_true)
stats_4 <- calculate_stats(results_clean$Y_hat_4_MAR, results_clean$Y_true)
# Format for printing
results_table <- data.frame(
Method = c("1. Y_hat(X_U, known)", "2. Y_hat(GREG)", "4. Y_hat(MAR)"),
Bias = c(stats_1["Bias"], stats_2["Bias"], stats_4["Bias"]),
Emp.Var = c(stats_1["Emp. Var"], stats_2["Emp. Var"], stats_4["Emp. Var"]),
MSE = c(stats_1["MSE"], stats_2["MSE"], stats_4["MSE"])
)
# Print results
cat(paste("Simulation Results (based on", nrow(results_clean), "successful runs):\n"))
cat(paste("True Population Mean (avg):", mean(results_clean$Y_true, na.rm = TRUE), "\n"))
cat(paste("Average Sample Size (n_NP):", mean(results_clean$n_NP, na.rm = TRUE), "\n\n"))
print(results_table, digits = 5)
# Compare to Table 5.2 (Emp. Var and MSE are x1000 in the paper)
results_table_scaled <- results_table
results_table_scaled$Emp.Var <- results_table_scaled$Emp.Var * 1000
results_table_scaled$MSE <- results_table_scaled$MSE * 1000
colnames(results_table_scaled)[3:4] <- c("Emp. Var * 1000", "MSE * 1000")
cat("\nResults scaled as in Table 5.2:\n")
print(results_table_scaled, digits = 5)
library(nloptr)
library(fastGHQuad)
install.packages("fastGHQuad")
library(nloptr)
library(fastGHQuad)
# Set up Gauss-Hermite quadrature for numerical integration (20 points for accuracy)
gh <- gaussHermiteData(20)
# Logistic function
logistic <- function(z) {
1 / (1 + exp(-z))
}
# Function to compute Pr(δ=1 | x; β, φ) using Gauss-Hermite quadrature
pr_delta_x <- function(mu, phi, x1, gh) {
y_nodes <- sqrt(2) * gh$x + mu
g_y <- logistic(phi[1] + phi[2] * x1 + phi[3] * y_nodes)
(1 / sqrt(pi)) * sum(gh$w * g_y)
}
# Function to compute partial integral from -Inf to upper for CDF numerator
pr_delta_partial <- function(mu, phi, x1, upper, gh) {
# This is approximate; for CDF, we need to integrate the integrand from -Inf to upper
# But for accuracy, we can use integrate for this, as GH is for -Inf to Inf
# To keep consistent, use R's integrate for partial
integrand <- function(y, mu, phi, x1) dnorm(y, mu, 1) * logistic(phi[1] + phi[2] * x1 + phi[3] * y)
integrate(integrand, lower = -Inf, upper = upper, mu = mu, phi = phi, x1 = x1)$value
}
# Log-likelihood function
log_lik <- function(theta, x1_S, x2_S, y_S, gh) {
beta <- theta[1:3]
phi <- theta[4:6]
mu_S <- beta[1] + beta[2] * x1_S + beta[3] * x2_S
f_U_log <- dnorm(y_S, mu_S, 1, log = TRUE)
z_y <- phi[1] + phi[2] * x1_S + phi[3] * y_S
log_pr_y <- log(logistic(z_y))
log_pr_x <- numeric(length(y_S))
for (k in 1:length(y_S)) {
log_pr_x[k] <- log(pr_delta_x(mu_S[k], phi, x1_S[k], gh))
}
sum(f_U_log + log_pr_y - log_pr_x)
}
# Constraint function (vector of 3 constraints for (1, x1, x2))
constraint_func <- function(theta, x1_U, x2_U, gh) {
beta <- theta[1:3]
phi <- theta[4:6]
mu_U <- beta[1] + beta[2] * x1_U + beta[3] * x2_U
pr_x_U <- numeric(length(x1_U))
for (j in 1:length(x1_U)) {
pr_x_U[j] <- pr_delta_x(mu_U[j], phi, x1_U[j], gh)
}
mean_pr_1 <- mean(pr_x_U * 1)
mean_pr_x1 <- mean(pr_x_U * x1_U)
mean_pr_x2 <- mean(pr_x_U * x2_U)
c(1 - mean_pr_1, mean(x1_U) - mean_pr_x1, mean(x2_U) - mean_pr_x2)
}
# Objective for nloptr (minimize -loglik)
obj_func <- function(theta, x1_S, x2_S, y_S, gh) {
-log_lik(theta, x1_S, x2_S, y_S, gh)
}
# Function to compute UNIF statistic
compute_unif <- function(theta, x1_S, x2_S, y_S, gh, M = 5) {
beta <- theta[1:3]
phi <- theta[4:6]
mu_S <- beta[1] + beta[2] * x1_S + beta[3] * x2_S
pr_x_S <- sapply(1:length(y_S), function(k) pr_delta_x(mu_S[k], phi, x1_S[k], gh))
T_i <- numeric(length(y_S))
for (k in 1:length(y_S)) {
numerator <- pr_delta_partial(mu_S[k], phi, x1_S[k], y_S[k], gh)
T_i[k] <- numerator / pr_x_S[k]
}
moments <- sapply(1:M, function(m) mean(T_i^m))
mu <- sapply(1:M, function(m) 1 / (m + 1))
Sigma <- matrix(0, M, M)
for (m in 1:M) {
for (l in 1:M) {
Sigma[m, l] <- 1 / (m + l + 1) - (1 / (m + 1)) * (1 / (l + 1))
}
diff <- moments - mu
unif_stat <- as.numeric(t(diff) %*% solve(Sigma) %*% diff)
unif_stat
}
# Simulation parameters
N <- 5000
R <- 1000  # Number of simulations; reduce for testing
beta_true <- c(-4, 1, 1)
phi_true <- c(-2, 1, 0.5)
# Vectors to store results
y_bar_true_vec <- numeric(R)
y_hat_xknown <- numeric(R)
y_hat_greg <- numeric(R)
unif_stats <- numeric(R)
for (r in 1:R) {
# Generate population
x1_U <- rnorm(N, 2, 1)
x2_U <- rnorm(N, 0, 1)
epsilon <- rnorm(N, 0, 1)
y_U <- beta_true[1] + beta_true[2] * x1_U + beta_true[3] * x2_U + epsilon
z_true <- phi_true[1] + phi_true[2] * x1_U + phi_true[3] * y_U
pi_true <- logistic(z_true)
delta <- rbinom(N, 1, pi_true)
S_idx <- which(delta == 1)
n_S <- length(S_idx)
x1_S <- x1_U[S_idx]
x2_S <- x2_U[S_idx]
y_S <- y_U[S_idx]
y_bar_true <- mean(y_U)
y_bar_true_vec[r] <- y_bar_true
# Initial guess for theta
theta0 <- c(-3, 1, 1, -1, 1, 0.5)
# Optimize with constraints
opts <- list(algorithm = "NLOPT_LD_AUGLAG_EQ",
xtol_rel = 1e-4,
maxeval = 10000,
local_opts = list(algorithm = "NLOPT_LD_MMA", xtol_rel = 1e-4))
res <- nloptr(x0 = theta0,
eval_f = obj_func,
eval_g_eq = function(theta) constraint_func(theta, x1_U, x2_U, gh),
opts = opts,
x1_S = x1_S, x2_S = x2_S, y_S = y_S, gh = gh)
theta_hat <- res$solution
beta_hat <- theta_hat[1:3]
phi_hat <- theta_hat[4:6]
# Compute Ŷ_Xknown (mean)
y_hat_xknown[r] <- mean(beta_hat[1] + beta_hat[2] * x1_U + beta_hat[3] * x2_U)
# Compute Ŷ_GREG
z_y_S <- phi_hat[1] + phi_hat[2] * x1_S + phi_hat[3] * y_S
pi_hat_S <- logistic(z_y_S)
k_S <- 1 / pi_hat_S
# Weighted LS for B_hat
df_S <- data.frame(y = y_S, x1 = x1_S, x2 = x2_S)
lm_w <- lm(y ~ x1 + x2, data = df_S, weights = k_S)
B_hat <- coef(lm_w)
# Sum_U x (vector sums)
sum_U_1 <- N
sum_U_x1 <- sum(x1_U)
sum_U_x2 <- sum(x2_U)
sum_tot_x <- c(sum_U_1, sum_U_x1, sum_U_x2)
# Sum_S k x
sum_k_1 <- sum(k_S * 1)
sum_k_x1 <- sum(k_S * x1_S)
sum_k_x2 <- sum(k_S * x2_S)
sum_k_x <- c(sum_k_1, sum_k_x1, sum_k_x2)
# GREG total
greg_total <- sum(k_S * y_S) + as.numeric(t(B_hat) %*% (sum_tot_x - sum_k_x))
y_hat_greg[r] <- greg_total / N
# Compute UNIF statistic
unif_stats[r] <- compute_unif(theta_hat, x1_S, x2_S, y_S, gh)
}
traceback()
library(nloptr)
library(fastGHQuad)
# Set up Gauss-Hermite quadrature for numerical integration (20 points for accuracy)
gh <- gaussHermiteData(20)
# Logistic function
logistic <- function(z) {
1 / (1 + exp(-z))
}
# Function to compute Pr(δ=1 | x; β, φ) using Gauss-Hermite quadrature
pr_delta_x <- function(mu, phi, x1, gh) {
y_nodes <- sqrt(2) * gh$x + mu
g_y <- logistic(phi[1] + phi[2] * x1 + phi[3] * y_nodes)
(1 / sqrt(pi)) * sum(gh$w * g_y)
}
# Function to compute partial integral from -Inf to upper for CDF numerator
pr_delta_partial <- function(mu, phi, x1, upper) {
integrand <- function(y, mu, phi, x1) dnorm(y, mu, 1) * logistic(phi[1] + phi[2] * x1 + phi[3] * y)
integrate(integrand, lower = -Inf, upper = upper, mu = mu, phi = phi, x1 = x1)$value
}
# Log-likelihood function
log_lik <- function(theta, x1_S, x2_S, y_S, gh) {
beta <- theta[1:3]
phi <- theta[4:6]
mu_S <- beta[1] + beta[2] * x1_S + beta[3] * x2_S
f_U_log <- dnorm(y_S, mu_S, 1, log = TRUE)
z_y <- phi[1] + phi[2] * x1_S + phi[3] * y_S
log_pr_y <- log(logistic(z_y))
log_pr_x <- numeric(length(y_S))
for (k in 1:length(y_S)) {
log_pr_x[k] <- log(pr_delta_x(mu_S[k], phi, x1_S[k], gh))
}
sum(f_U_log + log_pr_y - log_pr_x)
}
# Constraint function (vector of 3 constraints for (1, x1, x2))
constraint_func <- function(theta, x1_U, x2_U, gh) {
beta <- theta[1:3]
phi <- theta[4:6]
mu_U <- beta[1] + beta[2] * x1_U + beta[3] * x2_U
pr_x_U <- numeric(length(x1_U))
for (j in 1:length(x1_U)) {
pr_x_U[j] <- pr_delta_x(mu_U[j], phi, x1_U[j], gh)
}
mean_pr_1 <- mean(pr_x_U * 1)
mean_pr_x1 <- mean(pr_x_U * x1_U)
mean_pr_x2 <- mean(pr_x_U * x2_U)
c(1 - mean_pr_1, mean(x1_U) - mean_pr_x1, mean(x2_U) - mean_pr_x2)
}
# Objective for nloptr (minimize -loglik)
obj_func <- function(theta, x1_S, x2_S, y_S, gh) {
-log_lik(theta, x1_S, x2_S, y_S, gh)
}
# Function to compute UNIF statistic
compute_unif <- function(theta, x1_S, x2_S, y_S, gh, M = 5) {
beta <- theta[1:3]
phi <- theta[4:6]
mu_S <- beta[1] + beta[2] * x1_S + beta[3] * x2_S
pr_x_S <- sapply(1:length(y_S), function(k) pr_delta_x(mu_S[k], phi, x1_S[k], gh))
T_i <- numeric(length(y_S))
for (k in 1:length(y_S)) {
numerator <- pr_delta_partial(mu_S[k], phi, x1_S[k], y_S[k])
T_i[k] <- numerator / pr_x_S[k]
}
moments <- sapply(1:M, function(m) mean(T_i^m))
mu <- sapply(1:M, function(m) 1 / (m + 1))
Sigma <- matrix(0, M, M)
for (m in 1:M) {
for (l in 1:M) {
Sigma[m, l] <- 1 / (m + l + 1) - (1 / (m + 1)) * (1 / (l + 1))
}
diff <- moments - mu
unif_stat <- as.numeric(t(diff) %*% solve(Sigma) %*% diff)
unif_stat
}
# Simulation parameters
N <- 5000
R <- 1000  # Number of simulations; reduce for testing
beta_true <- c(-4, 1, 1)
phi_true <- c(-2, 1, 0.5)
# Vectors to store results
y_bar_true_vec <- numeric(R)
y_hat_xknown <- numeric(R)
y_hat_greg <- numeric(R)
unif_stats <- numeric(R)
for (r in 1:R) {
# Generate population
x1_U <- rnorm(N, 2, 1)
x2_U <- rnorm(N, 0, 1)
epsilon <- rnorm(N, 0, 1)
y_U <- beta_true[1] + beta_true[2] * x1_U + beta_true[3] * x2_U + epsilon
z_true <- phi_true[1] + phi_true[2] * x1_U + phi_true[3] * y_U
pi_true <- logistic(z_true)
delta <- rbinom(N, 1, pi_true)
S_idx <- which(delta == 1)
n_S <- length(S_idx)
x1_S <- x1_U[S_idx]
x2_S <- x2_U[S_idx]
y_S <- y_U[S_idx]
y_bar_true <- mean(y_U)
y_bar_true_vec[r] <- y_bar_true
# Initial guess for theta
theta0 <- c(-3, 1, 1, -1, 1, 0.5)
# Optimize with constraints
opts <- list(algorithm = "NLOPT_LD_AUGLAG_EQ",
xtol_rel = 1e-4,
maxeval = 10000,
local_opts = list(algorithm = "NLOPT_LD_MMA", xtol_rel = 1e-4))
res <- nloptr(x0 = theta0,
eval_f = obj_func,
eval_g_eq = function(theta, ...) constraint_func(theta, x1_U, x2_U, gh),
opts = opts,
x1_S = x1_S, x2_S = x2_S, y_S = y_S, gh = gh)
theta_hat <- res$solution
beta_hat <- theta_hat[1:3]
phi_hat <- theta_hat[4:6]
# Compute Ŷ_Xknown (mean)
y_hat_xknown[r] <- mean(beta_hat[1] + beta_hat[2] * x1_U + beta_hat[3] * x2_U)
# Compute Ŷ_GREG
z_y_S <- phi_hat[1] + phi_hat[2] * x1_S + phi_hat[3] * y_S
pi_hat_S <- logistic(z_y_S)
k_S <- 1 / pi_hat_S
# Weighted LS for B_hat
df_S <- data.frame(y = y_S, x1 = x1_S, x2 = x2_S)
lm_w <- lm(y ~ x1 + x2, data = df_S, weights = k_S)
B_hat <- coef(lm_w)
# Sum_U x (vector sums)
sum_U_1 <- N
sum_U_x1 <- sum(x1_U)
sum_U_x2 <- sum(x2_U)
sum_tot_x <- c(sum_U_1, sum_U_x1, sum_U_x2)
# Sum_S k x
sum_k_1 <- sum(k_S * 1)
sum_k_x1 <- sum(k_S * x1_S)
sum_k_x2 <- sum(k_S * x2_S)
sum_k_x <- c(sum_k_1, sum_k_x1, sum_k_x2)
# GREG total
greg_total <- sum(k_S * y_S) + as.numeric(t(B_hat) %*% (sum_tot_x - sum_k_x))
y_hat_greg[r] <- greg_total / N
# Compute UNIF statistic
unif_stats[r] <- compute_unif(theta_hat, x1_S, x2_S, y_S, gh)
}
traceback()
library(nloptr)
library(fastGHQuad)
# Set up Gauss-Hermite quadrature for numerical integration (20 points for accuracy)
gh <- gaussHermiteData(20)
# Logistic function
logistic <- function(z) {
1 / (1 + exp(-z))
}
# Function to compute Pr(δ=1 | x; β, φ) using Gauss-Hermite quadrature
pr_delta_x <- function(mu, phi, x1, gh) {
y_nodes <- sqrt(2) * gh$x + mu
g_y <- logistic(phi[1] + phi[2] * x1 + phi[3] * y_nodes)
(1 / sqrt(pi)) * sum(gh$w * g_y)
}
# Function to compute partial integral from -Inf to upper for CDF numerator
pr_delta_partial <- function(mu, phi, x1, upper) {
integrand <- function(y) dnorm(y, mu, 1) * logistic(phi[1] + phi[2] * x1 + phi[3] * y)
integrate(integrand, lower = -Inf, upper = upper)$value
}
# Log-likelihood function
log_lik <- function(theta, x1_S, x2_S, y_S, gh) {
beta <- theta[1:3]
phi <- theta[4:6]
mu_S <- beta[1] + beta[2] * x1_S + beta[3] * x2_S
f_U_log <- dnorm(y_S, mu_S, 1, log = TRUE)
z_y <- phi[1] + phi[2] * x1_S + phi[3] * y_S
log_pr_y <- log(logistic(z_y))
log_pr_x <- numeric(length(y_S))
for (k in 1:length(y_S)) {
log_pr_x[k] <- log(pr_delta_x(mu_S[k], phi, x1_S[k], gh))
}
sum(f_U_log + log_pr_y - log_pr_x)
}
# Constraint function (vector of 3 constraints for (1, x1, x2))
constraint_func <- function(theta, x1_U, x2_U, gh) {
beta <- theta[1:3]
phi <- theta[4:6]
mu_U <- beta[1] + beta[2] * x1_U + beta[3] * x2_U
pr_x_U <- numeric(length(x1_U))
for (j in 1:length(x1_U)) {
pr_x_U[j] <- pr_delta_x(mu_U[j], phi, x1_U[j], gh)
}
mean_pr_1 <- mean(pr_x_U * 1)
mean_pr_x1 <- mean(pr_x_U * x1_U)
mean_pr_x2 <- mean(pr_x_U * x2_U)
c(1 - mean_pr_1, mean(x1_U) - mean_pr_x1, mean(x2_U) - mean_pr_x2)
}
# Objective for nloptr (minimize -loglik)
obj_func <- function(theta, x1_S, x2_S, y_S, gh) {
-log_lik(theta, x1_S, x2_S, y_S, gh)
}
# Function to compute UNIF statistic
compute_unif <- function(theta, x1_S, x2_S, y_S, gh, M = 5) {
beta <- theta[1:3]
phi <- theta[4:6]
mu_S <- beta[1] + beta[2] * x1_S + beta[3] * x2_S
pr_x_S <- sapply(1:length(y_S), function(k) pr_delta_x(mu_S[k], phi, x1_S[k], gh))
T_i <- numeric(length(y_S))
for (k in 1:length(y_S)) {
numerator <- pr_delta_partial(mu_S[k], phi, x1_S[k], y_S[k])
T_i[k] <- numerator / pr_x_S[k]
}
moments <- sapply(1:M, function(m) mean(T_i^m))
mu <- sapply(1:M, function(m) 1 / (m + 1))
Sigma <- matrix(0, M, M)
for (m in 1:M) {
for (l in 1:M) {
Sigma[m, l] <- 1 / (m + l + 1) - (1 / (m + 1)) * (1 / (l + 1))
}
diff <- moments - mu
unif_stat <- as.numeric(t(diff) %*% solve(Sigma) %*% diff)
unif_stat
}
# Simulation parameters
N <- 5000
R <- 1000  # Number of simulations; reduce for testing
beta_true <- c(-4, 1, 1)
phi_true <- c(-2, 1, 0.5)
# Vectors to store results
y_bar_true_vec <- numeric(R)
y_hat_xknown <- numeric(R)
y_hat_greg <- numeric(R)
unif_stats <- numeric(R)
for (r in 1:R) {
# Generate population
x1_U <- rnorm(N, 2, 1)
x2_U <- rnorm(N, 0, 1)
epsilon <- rnorm(N, 0, 1)
y_U <- beta_true[1] + beta_true[2] * x1_U + beta_true[3] * x2_U + epsilon
z_true <- phi_true[1] + phi_true[2] * x1_U + phi_true[3] * y_U
pi_true <- logistic(z_true)
delta <- rbinom(N, 1, pi_true)
S_idx <- which(delta == 1)
n_S <- length(S_idx)
x1_S <- x1_U[S_idx]
x2_S <- x2_U[S_idx]
y_S <- y_U[S_idx]
y_bar_true <- mean(y_U)
y_bar_true_vec[r] <- y_bar_true
# Initial guess for theta
theta0 <- c(-3, 1, 1, -1, 1, 0.5)
# Optimize with constraints
opts <- list(algorithm = "NLOPT_LD_AUGLAG_EQ",
xtol_rel = 1e-4,
maxeval = 10000,
local_opts = list(algorithm = "NLOPT_LD_MMA", xtol_rel = 1e-4))
res <- nloptr(x0 = theta0,
eval_f = obj_func,
eval_g_eq = function(theta) constraint_func(theta, x1_U, x2_U, gh),
opts = opts,
x1_S = x1_S, x2_S = x2_S, y_S = y_S, gh = gh)
theta_hat <- res$solution
beta_hat <- theta_hat[1:3]
phi_hat <- theta_hat[4:6]
# Compute Ŷ_Xknown (mean)
y_hat_xknown[r] <- mean(beta_hat[1] + beta_hat[2] * x1_U + beta_hat[3] * x2_U)
# Compute Ŷ_GREG
z_y_S <- phi_hat[1] + phi_hat[2] * x1_S + phi_hat[3] * y_S
pi_hat_S <- logistic(z_y_S)
k_S <- 1 / pi_hat_S
# Weighted LS for B_hat
df_S <- data.frame(y = y_S, x1 = x1_S, x2 = x2_S)
lm_w <- lm(y ~ x1 + x2, data = df_S, weights = k_S)
B_hat <- coef(lm_w)
# Sum_U x (vector sums)
sum_U_1 <- N
sum_U_x1 <- sum(x1_U)
sum_U_x2 <- sum(x2_U)
sum_tot_x <- c(sum_U_1, sum_U_x1, sum_U_x2)
# Sum_S k x
sum_k_1 <- sum(k_S * 1)
sum_k_x1 <- sum(k_S * x1_S)
sum_k_x2 <- sum(k_S * x2_S)
sum_k_x <- c(sum_k_1, sum_k_x1, sum_k_x2)
# GREG total
greg_total <- sum(k_S * y_S) + as.numeric(t(B_hat) %*% (sum_tot_x - sum_k_x))
y_hat_greg[r] <- greg_total / N
# Compute UNIF statistic
unif_stats[r] <- compute_unif(theta_hat, x1_S, x2_S, y_S, gh)
}
gc()
